{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2005126-6d9a-4dbf-a079-f096fc03667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30991, 277) (200351, 277)\n",
      "(37441, 277) (14481, 277)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_beats = pd.read_csv(\"train_beats.csv\")\n",
    "train_patients = pd.read_csv(\"train_patients.csv\")\n",
    "\n",
    "test_beats = pd.read_csv(\"test_beats.csv\")\n",
    "test_patients = pd.read_csv(\"test_patients.csv\")\n",
    "\n",
    "print(train_beats.shape, train_patients.shape)\n",
    "print(test_beats.shape, test_patients.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b68c40-ddba-4ff1-a665-2923f700cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt(\"train_patients.csv\", delimiter=\",\")\n",
    "test  = np.genfromtxt(\"test_patients.csv\", delimiter=\",\")\n",
    "\n",
    "X_train = train[:, :-2]\n",
    "y_train = train[:, -2]\n",
    "\n",
    "X_test = test[:, :-2]\n",
    "y_test = test[:, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10535eb7-c9b1-49a8-b570-41da3a00d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8245408092804861\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.77      0.86      9363\n",
      "         2.0       0.00      0.00      0.00         0\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.57      0.95      0.71      1087\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       0.36      0.88      0.51       387\n",
      "         7.0       0.73      0.81      0.77      1138\n",
      "         8.0       0.97      0.99      0.98      2507\n",
      "\n",
      "    accuracy                           0.82     14482\n",
      "   macro avg       0.45      0.55      0.48     14482\n",
      "weighted avg       0.92      0.82      0.86     14482\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7180   61   37  756  455  582  284    8]\n",
      " [   0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0]\n",
      " [   9    2    1 1032    5   18    9   11]\n",
      " [   0    0    0    0    0    0    0    0]\n",
      " [  21    4    0   11    2  340    9    0]\n",
      " [  53   67    7   19   12   16  917   47]\n",
      " [   1    1    0    2    0    0   31 2472]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c35e77-5988-448c-8c36-e6d8f8973de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Initialize SVM classifier\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "# Train\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d875b43-55c4-4491-87e6-b80c664de55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute permutation importance\n",
    "result = permutation_importance(\n",
    "    svm_model,              # trained SVM model\n",
    "    X_test_scaled,          # test features (scaled)\n",
    "    y_test,                 # true labels\n",
    "    n_repeats=10,           # number of shuffling rounds\n",
    "    random_state=42,\n",
    "    scoring='accuracy'      # can also use 'f1_macro', etc.\n",
    ")\n",
    "\n",
    "# Get feature importance\n",
    "importances = result.importances_mean\n",
    "std = result.importances_std\n",
    "feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "\n",
    "# Print feature importances\n",
    "print(\"Feature importances (permutation):\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{feature_names[i]}: {importances[i]:.4f} Â± {std[i]:.4f}\")\n",
    "\n",
    "# Optional: plot the importances\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(len(importances)), importances[sorted_idx], yerr=std[sorted_idx])\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in sorted_idx], rotation=90)\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.title(\"Feature Importance (Permutation)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c8353e1-d871-48f0-a73d-6a302955743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy: 0.8227\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     23\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, preds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    488\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    490\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    491\u001b[0m )(\n\u001b[0;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    493\u001b[0m         t,\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    495\u001b[0m         X,\n\u001b[0;32m    496\u001b[0m         y,\n\u001b[0;32m    497\u001b[0m         sample_weight,\n\u001b[0;32m    498\u001b[0m         i,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    500\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    501\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    502\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    190\u001b[0m         X,\n\u001b[0;32m    191\u001b[0m         y,\n\u001b[0;32m    192\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    193\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    194\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    195\u001b[0m     )\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression(max_iter=500),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=300),\n",
    "    \"SVM\": SVC(probability=True)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name in [\"LR\", \"SVM\"]:\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results[name] = acc\n",
    "    print(f\"{name} accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a48b99-2774-472d-99c1-0545688367a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "for name, model in models.items():\n",
    "\n",
    "    print(\"\\n### Permutation Importance for\", name)\n",
    "\n",
    "    if name in [\"LR\", \"SVM\"]:\n",
    "        r = permutation_importance(model, X_test_scaled, y_test, n_repeats=10)\n",
    "        feature_names = X_train.columns\n",
    "    else:\n",
    "        r = permutation_importance(model, X_test, y_test, n_repeats=10)\n",
    "        feature_names = X_train.columns\n",
    "\n",
    "    sorted_idx = r.importances_mean.argsort()\n",
    "\n",
    "    plt.figure(figsize=(6,8))\n",
    "    plt.barh(feature_names[sorted_idx[-15:]], r.importances_mean[sorted_idx[-15:]])\n",
    "    plt.title(f\"Top 15 Permutation Importance: {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23c118-5b99-4502-ba78-9b8e870437f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(models[\"XGB\"])\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f05ff-3bb9-4e02-ae14-bbb538c7c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(models[\"LR\"], X_train)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6c0b2-e420-4441-a8e1-889e494c297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=list(set(y_train)),\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# explain one sample\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test.iloc[5],\n",
    "    predict_fn=models[\"RF\"].predict_proba\n",
    ")\n",
    "\n",
    "exp.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba02190-c9e0-453d-a492-bb45fc71a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c316fd7-21d7-4dff-9de5-79d57ba5ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=len(set(y_train)))\n",
    "clusters = kmeans.fit_predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c541b-9f21-411e-9ea0-5cf9369ed714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='viridis')\n",
    "plt.title(\"K-means Clusters (PCA-reduced)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
